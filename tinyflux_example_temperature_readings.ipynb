{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55174a81-43fa-4d7c-a2d4-42fd1becd16e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tinyflux: Example with fictious temperature measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8df3dd",
   "metadata": {},
   "source": [
    "## Import Python Libraries und Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b027d889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tinyflux import TinyFlux, Point, FieldQuery, TagQuery, TimeQuery\n",
    "from datetime import datetime, timezone, timedelta #querys welche gebraucht werden\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Abkürzungen für Query-Typen. Für die Übersichtlichkeit -> Ebenfalls in der Prüfung übernehmen\n",
    "time = TimeQuery()\n",
    "tags = TagQuery()\n",
    "field = FieldQuery()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26250af4-2910-4da6-86bc-6c649d0791d3",
   "metadata": {},
   "source": [
    "## Load function for creating a dataframe from query results into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "85718b1e-8fa0-422e-add9-e462f1147bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Kann 1:1 übernommen werden, einfach attribute anpassen wie time, sensor_id etc.\n",
    "\n",
    "# Define the function to transform the list of Point objects into a DataFrame\n",
    "def points_to_dataframe(points_list):\n",
    "    data = []\n",
    "    \n",
    "    # Extract the relevant information\n",
    "    for point in points_list:\n",
    "        data.append({\n",
    "            \"time\": point.time,  # Access time attribute\n",
    "            \"sensor_id\": point.tags['sensor_id'],  # Access sender_id from tags dictionary\n",
    "            \"temperature\": point.fields['temperature'],  # Access receiver_id from tags dictionary\n",
    "            \"status\": point.tags['status'],# Access status from tags dictionary\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Convert time to datetime\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4f5b7b-2304-44f2-be55-daa9361b84f9",
   "metadata": {},
   "source": [
    "## Initialize the TinyFlux database\n",
    "## (Leere temperature.db wird generiert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "36ca64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung der Tinyflux-Datenbank (wird bereitgestellt)\n",
    "db = TinyFlux(\"temperatures.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91fd6bf-305a-4bdb-bcc1-1490d3c5319e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing a CSV file and show first descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ef32ffa2-1859-48af-a78c-0f1b5748fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV-Datei in Dataframe laden\n",
    "df = pd.read_csv('example_data/synthetic_temperature_readings.csv')\n",
    "\n",
    "# Das Format des Zeitstempels in Pandas setzen\n",
    "df['time']= pd.to_datetime(df['time'], format='mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e96111-8d86-42e6-abe6-57d49ec7e487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Erste 10 Records des Dataframes anzeigen\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9438c555-299a-4109-bf01-ebf11d7de003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e328c-b0c2-4fb3-ab50-e92c613fc801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deskriptive Statistiken des Dataframes\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cd85bc-41fb-41d0-aa2c-0ba1bb16e853",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Writing a CSV file into Tinyflux / Task1 \n",
    "## (temperatures.db wird mit Daten gefüllt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cfd07b2d-1b23-4c93-b3f9-ccc3dcc73c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV and insert data into TinyFlux\n",
    "with open(\"example_data/synthetic_temperature_readings.csv\", mode=\"r\") as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        point = Point(\n",
    "            time=datetime.strptime(row[\"time\"], \"%Y-%m-%d %H:%M:%S\"), #here is time-granularity defined, has to be as in csv file\n",
    "            # example daily granularity: time = datetime.strptime(row[\"time\"], \"%Y-%m-%d\")\n",
    "            measurement=\"blockchain_transactions\", #tabellenname\n",
    "            fields={\n",
    "                \"temperature\": float(row[\"temperature\"])\n",
    "                },  # Only numeric fields\n",
    "            tags={\n",
    "                \"sensor_id\": row[\"sensor_id\"],\n",
    "                \"status\": row[\"status\"],  # Move non-numeric fields to tags\n",
    "            }\n",
    "        )\n",
    "        db.insert(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443c15e3-111b-4cd5-b71a-189e040801cb",
   "metadata": {},
   "source": [
    "## Writing manually into Tinyflux / Task2\n",
    "## (in temperatures.db \"default\" data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3e36b8-11e5-48b3-babf-ed6558f47728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create manual records\n",
    "p1 = Point(\n",
    "    time=datetime(2024, 1, 1, 0, 0, 0, tzinfo=timezone.utc), #Granularitätsstufe Jahr, Monat, Tag, Stunden\n",
    "    tags={\"sensor_id\": \"20\", \"status\": \"operational\"},\n",
    "    fields={\"temperature\": 15.240971}\n",
    ")\n",
    "\n",
    "p2 = Point(\n",
    "    time=datetime(2024, 1, 1, 0, 0, 0, tzinfo=timezone.utc),\n",
    "    tags={\"sensor_id\": \"30\", \"status\": \"maintenance\"},\n",
    "    fields={\"temperature\": 20.517200}\n",
    ")\n",
    "\n",
    "# Insert into the DB.\n",
    "db.insert_multiple([p1, p2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea6293-b05e-45a5-a393-a10bd7418a1e",
   "metadata": {},
   "source": [
    "## Querying by Time / Task3\n",
    "## Greater than or equal to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d536be5-d641-476c-9d36-6e7a0a8bebe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definieren der Query\n",
    "time_query_conditions = (time >= datetime(2024, 1, 1, 0, 0, 0, tzinfo=timezone.utc)) # greater than or equal to January 1, 2024, at midnight (in UTC).\n",
    "\n",
    "# Datenabfrage mittels der definierten Query\n",
    "my_results = db.search(time_query_conditions)\n",
    "\n",
    "# Erstellung eines Dataframes aus den Query-Resultaten\n",
    "# Die ugehörige Funktion \"points_to_dataframe()\" wurde zu Beginn dieses Notebooks in den Arbeitsspeicher geladen\n",
    "df_result_time = points_to_dataframe(my_results)\n",
    "df_result_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8191cc42",
   "metadata": {},
   "source": [
    "## Querying by time / Task3\n",
    "## Between two specific Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b48ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Records Between Two Specific Dates/Times\n",
    "start_time = datetime(2024, 1, 1, 0, 0, 0, tzinfo=timezone.utc)\n",
    "end_time = datetime(2024, 12, 31, 23, 59, 59, tzinfo=timezone.utc)\n",
    "\n",
    "# Query records between two dates\n",
    "time_query_conditions = (start_time <= time <= end_time)\n",
    "\n",
    "# Datenabfrage mittels der definierten Query\n",
    "my_results = db.search(time_query_conditions)\n",
    "\n",
    "# Erstellung eines Dataframes aus den Query-Resultaten\n",
    "# Die ugehörige Funktion \"points_to_dataframe()\" wurde zu Beginn dieses Notebooks in den Arbeitsspeicher geladen\n",
    "df_result_time = points_to_dataframe(my_results)\n",
    "df_result_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1427d1",
   "metadata": {},
   "source": [
    "## Querying by time / Task3\n",
    "## For a specific day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c492a4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define query conditions for a specific day (e.g., September 15, 2024)\n",
    "start_time = datetime(2024, 9, 15, 0, 0, 0, tzinfo=timezone.utc)\n",
    "end_time = datetime(2024, 9, 15, 23, 59, 59, tzinfo=timezone.utc)\n",
    "\n",
    "# Query records between two dates\n",
    "time_query_conditions = (start_time <= time <= end_time)\n",
    "\n",
    "# Datenabfrage mittels der definierten Query\n",
    "my_results = db.search(time_query_conditions)\n",
    "\n",
    "# Erstellung eines Dataframes aus den Query-Resultaten\n",
    "# Die ugehörige Funktion \"points_to_dataframe()\" wurde zu Beginn dieses Notebooks in den Arbeitsspeicher geladen\n",
    "df_result_time = points_to_dataframe(my_results)\n",
    "df_result_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fe0b20",
   "metadata": {},
   "source": [
    "## Querying by time / Task3\n",
    "## For a specific time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e5b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definieren der Query\n",
    "time_query_conditions = (time == datetime(2024, 1, 1, 0, 0, 0, tzinfo=timezone.utc)) # greater than or equal to January 1, 2024, at midnight (in UTC).\n",
    "\n",
    "# Datenabfrage mittels der definierten Query\n",
    "my_results = db.search(time_query_conditions)\n",
    "\n",
    "# Erstellung eines Dataframes aus den Query-Resultaten\n",
    "# Die ugehörige Funktion \"points_to_dataframe()\" wurde zu Beginn dieses Notebooks in den Arbeitsspeicher geladen\n",
    "df_result_time = points_to_dataframe(my_results)\n",
    "df_result_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda0d01a-b518-4f47-b9d1-fb10009fa4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result_time.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826c803-6910-4550-9326-0ac62c2a27ad",
   "metadata": {},
   "source": [
    "## Querying by Tag / Task5\n",
    "## Specific Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c638303-0b35-4e5d-8454-e877e7f0f868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.status.unique() # gibt alle Werte für Tag \"status\" an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "04c1636b-1760-4dcd-bdf2-f109d9a9c443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definieren der Queries\n",
    "tag_query_conditions_operational = (tags.status == \"operational\") # abfrage nach bestimmten tags\n",
    "tag_query_conditions_maintenance = (tags.status == \"maintenance\")\n",
    "tag_query_conditions_offline = (tags.status == \"offline\")\n",
    "\n",
    "# Datenabfrage mittels der definierten Queries\n",
    "my_results_operational = db.search(tag_query_conditions_operational)\n",
    "my_results_maintenance = db.search(tag_query_conditions_maintenance)\n",
    "my_results_offline = db.search(tag_query_conditions_offline)\n",
    "\n",
    "# Erstellung eines Dataframes aus den Query-Resultaten\n",
    "df_result_tag_operational = points_to_dataframe(my_results_operational)\n",
    "df_result_tag_maintenance = points_to_dataframe(my_results_maintenance)\n",
    "df_result_tag_offline = points_to_dataframe(my_results_offline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea5d85b",
   "metadata": {},
   "source": [
    "## How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab41caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_by_location = df.groupby(['status'])\n",
    "\n",
    "my_results_operational = db.search(temp_by_location)\n",
    "\n",
    "df_result_tag_operational = points_to_dataframe(my_results_operational)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c479763-8c86-4324-96ed-35a78e60b510",
   "metadata": {},
   "source": [
    "### Dataframe with operational status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f6172-af5a-4dd0-9282-bca99e77eba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result_tag_operational.head(10) # Anzahl Abfragen aus dem Resultat \"df_result_tag_operational\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dfeeed-4d20-41f6-9907-5dad35d3e598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result_tag_operational.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3262c698-87cb-4f23-a57e-c6ca4d5799ec",
   "metadata": {},
   "source": [
    "### Dataframe with maintenance status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3dd781-ca81-4e32-b258-b32d7b087cdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result_tag_maintenance.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e740dac-e4d0-4c60-815d-92ccb35cb27e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result_tag_maintenance.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0543041a-8b26-40ef-89f1-b7a9b9ae46a4",
   "metadata": {},
   "source": [
    "### Dataframe with offline status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d22b6c-6f78-4be8-9291-22bf747906a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result_tag_offline.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244eb36-827d-4cc4-9be9-fe6642dc561f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result_tag_maintenance.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae776a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unschöne Variante\n",
    "tag_query = TagQuery()\n",
    "q1 = db.search(tag_query.status == \"operational\")\n",
    "\n",
    "for x in q1: \n",
    "    print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6964504d-24f4-407a-adb3-a054f4ae813f",
   "metadata": {},
   "source": [
    "## Querying by Field / Task4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21d68eb-4a7e-443d-8a9c-17c1abd5c400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definieren der Queries\n",
    "field_query_conditions = (field.temperature > 0)\n",
    "\n",
    "# Datenabfrage mittels der definierten Queries\n",
    "my_results = db.search(field_query_conditions)\n",
    "\n",
    "# Erstellung eines Dataframes aus den Query-Resultaten\n",
    "# Die ugehörige Funktion \"points_to_dataframe()\" wurde zu Beginn dieses Notebooks in den Arbeitsspeicher geladen\n",
    "df_result_field = points_to_dataframe(my_results)\n",
    "\n",
    "print(\"\\n Dataframe with temperature measurements > 0:\")\n",
    "df_result_field.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbdec2a-cb89-4373-b043-281fa8d365a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result_field.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa97c2",
   "metadata": {},
   "source": [
    "## Querying by Field / Task4\n",
    "## total or average temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c27099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definieren der Queries / temperature grösser als 0 Grad\n",
    "field_query_conditions = (field.temperature > 0)\n",
    "\n",
    "# Datenabfrage mittels der definierten Queries\n",
    "my_results = db.search(field_query_conditions)\n",
    "\n",
    "# Erstellung eines Dataframes aus den Query-Resultaten\n",
    "df_result_field = points_to_dataframe(my_results)\n",
    "\n",
    "# Calculate total and average temperature\n",
    "total_temperature = df_result_field['temperature'].sum()\n",
    "average_temperature = df_result_field['temperature'].mean()\n",
    "\n",
    "# Print the results\n",
    "# print(\"\\nDataframe with temperature measurements > 0:\")\n",
    "# print(df_result_field.head(2))  # Display the first 2 records\n",
    "print(f\"\\nTotal temperature: {total_temperature}\")\n",
    "print(f\"Average temperature: {average_temperature}\")\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "\n",
    "# Definieren der Queries / measured before Mach 31 2023\n",
    "time_query_conditions = (time < datetime(2023, 3, 31, 0, 0, 0, tzinfo=timezone.utc))\n",
    "\n",
    "# Datenabfrage mittels der definierten Queries\n",
    "my_results = db.search(time_query_conditions)\n",
    "\n",
    "# Erstellung eines Dataframes aus den Query-Resultaten\n",
    "df_result_field = points_to_dataframe(my_results)\n",
    "\n",
    "# Calculate total and average temperature\n",
    "total_temperature = df_result_field['temperature'].sum()\n",
    "average_temperature = df_result_field['temperature'].mean()\n",
    "\n",
    "# Print the results\n",
    "# print(\"\\nDataframe with temperature measurements > 0:\")\n",
    "# print(df_result_field.head(2))  # Display the first 2 records\n",
    "print(f\"\\nTotal temperature: {total_temperature}\")\n",
    "print(f\"Average temperature: {average_temperature}\")\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "\n",
    "# Give average temperature of each status-value\n",
    "temp_by_location = df.groupby(['status'])['temperature'].mean()\n",
    "\n",
    "print(temp_by_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d62873-5db5-4b24-9bd5-dac526153f7c",
   "metadata": {},
   "source": [
    "## Variations of combining queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1081e95c-3f27-4c3b-b817-e3087fc84fe4",
   "metadata": {},
   "source": [
    "### Querying by Time and Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773e3365-e696-4048-aa0c-b007309fce29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Querying all temperatures, that were measured before Mach 31 2023 with the status \"operational\"\n",
    "\n",
    "# Definieren der Queries\n",
    "time_query_conditions = (time < datetime(2023, 3, 31, 0, 0, 0, tzinfo=timezone.utc))\n",
    "tag_query_conditions = (tags.status == \"operational\")\n",
    "\n",
    "# Datenabfrage mittels der definierten Queries\n",
    "my_results = db.search(time_query_conditions & tag_query_conditions)\n",
    "\n",
    "# Erstellung eines Dataframes aus den Query-Resultaten\n",
    "# Die ugehörige Funktion \"points_to_dataframe()\" wurde zu Beginn dieses Notebooks in den Arbeitsspeicher geladen\n",
    "df_result_time_tag = points_to_dataframe(my_results)\n",
    "df_result_time_tag.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5114a6d-41be-4336-880d-69ae76b022cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result_time_tag.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe1abaa-50e5-4b06-bf70-57290c712b1e",
   "metadata": {},
   "source": [
    "### Querying by Tag and Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f16b99-89ef-4dab-9560-b0eb82442c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Querying all temperatures higher than 20 degrees and with the status \"maintenance\"\n",
    "\n",
    "# Definieren der Queries\n",
    "tag_query_conditions = (tags.status == \"maintenance\")\n",
    "field_query_conditions = (field.temperature > 20.0)\n",
    "\n",
    "# Datenabfrage mittels der definierten Queries\n",
    "my_results = db.search(tag_query_conditions & field_query_conditions)\n",
    "\n",
    "# Erstellung eines Dataframes aus den Query-Resultaten\n",
    "# Die ugehörige Funktion \"points_to_dataframe()\" wurde zu Beginn dieses Notebooks in den Arbeitsspeicher geladen\n",
    "df_result_tag_field = points_to_dataframe(my_results)\n",
    "df_result_tag_field.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe3c8f2-4525-44bb-b1c4-cb1d72a430aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result_tag_field.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbed170-9143-48df-9819-5c575e913d87",
   "metadata": {},
   "source": [
    "## Variations of queries with multiple AND and OR conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e71b0d7-11e3-44f3-96d1-057a73c029bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Querying all measurements during winter months with temperatures below 0\n",
    "# OR conditions are separated with \"|\" (not to be confused with \"/\", see example below)\n",
    "\n",
    "# Definieren der Queries\n",
    "time_query_conditions = (time <= datetime(2023, 2, 28, 0, 0, 0, tzinfo=timezone.utc)) | (time >= datetime(2023, 12, 1, tzinfo=timezone.utc)) # \"or\" mit |\n",
    "field_query_conditions = (field.temperature < 0.0)\n",
    "\n",
    "# Datenabfrage mittels der definierten Queries\n",
    "my_results = db.search(time_query_conditions & field_query_conditions)\n",
    "\n",
    "# Erstellung eines Dataframes aus den Query-Resultaten\n",
    "# Die ugehörige Funktion \"points_to_dataframe()\" wurde zu Beginn dieses Notebooks in den Arbeitsspeicher geladen\n",
    "df_result_time_field = points_to_dataframe(my_results)\n",
    "df_result_time_field.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2219dbe0-3395-4c59-b6ec-a65ee1f6a078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result_time_field.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239977eb-4e57-46b0-9ae2-78b2b28d83ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Querying all measurements during summer months with temperatures above 0\n",
    "# AND conditions are separated with \"&\"\n",
    "\n",
    "# Definieren der Queries\n",
    "time_query_conditions = (time <= datetime(2023, 8, 31, 0, 0, 0, tzinfo=timezone.utc)) & (time >= datetime(2023, 6, 1, tzinfo=timezone.utc))\n",
    "field_query_conditions = (field.temperature > 0.0)\n",
    "\n",
    "# Datenabfrage mittels der definierten Queries\n",
    "my_results = db.search(time_query_conditions & field_query_conditions)\n",
    "\n",
    "# Erstellung eines Dataframes aus den Query-Resultaten\n",
    "# Die ugehörige Funktion \"points_to_dataframe()\" wurde zu Beginn dieses Notebooks in den Arbeitsspeicher geladen\n",
    "df_result_time_field_2 = points_to_dataframe(my_results)\n",
    "df_result_time_field_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd74e4-bfa1-4d64-8493-c86ace2a31c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_result_time_field_2.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e4f9d3",
   "metadata": {},
   "source": [
    "## How Tags Are Useful for Organizing and Filtering Data in a Time-Series Database:\n",
    "\n",
    "### Tags in a time-series database (like TinyFlux, InfluxDB, etc.) are key-value pairs that help organize and filter data more efficiently. Here's why they are important:\n",
    "\n",
    "### - Efficient Filtering: Tags allow for fast querying and filtering of records. For example, filtering all data where location=\"Zurich\" allows you to quickly retrieve data points related to that specific location without needing to search through the entire dataset.\n",
    "\n",
    "### - Group and Aggregate Data: Tags can be used to group and aggregate data, as shown above. You can group records by any tag (e.g., location, device_type, status), which is useful for reporting and trend analysis. For example, analyzing the average temperature for each location or counting the number of sensor devices.\n",
    "\n",
    "### - Improved Data Organization: In time-series databases, tags categorize data meaningfully. A sensor_id or location tag gives context to each data point, making it easier to work with complex datasets.\n",
    "\n",
    "### - Optimized Storage: Tags are indexed efficiently, allowing for fast lookups. Unlike fields (which store raw data), tags are meant for frequent queries and indexing, making the database more efficient when handling large datasets.\n",
    "\n",
    "### In summary, tags are crucial in a time-series database as they enable faster searches, data organization, and aggregation, making it easier to extract insights from large sets of time-series data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
